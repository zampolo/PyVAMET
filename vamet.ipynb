{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual attention models + eye traking\n",
    "## Introduction\n",
    "\n",
    "This is about using visual attention models to improve the performance of low-cost eye trackers. \n",
    "\n",
    "## Paper 1\n",
    "**Title:** 3D gaze estimation with a single camera without IR illumination \n",
    "\n",
    "**Authors:** Chen, Jixu and Ji, Qiang \n",
    "\n",
    "**Where:** 2008 19th International Conference on Pattern Recognition \n",
    "\n",
    "**Year:** 2008\n",
    "\n",
    "**Keywords:** 3D gaze estimation, facial feature, > 3°-accuracy, single camera, head free\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "### 1. Introduction:\n",
    "  * Gaze tracking: determination of the point-of-gaze in space, or the visual axis of the eye\n",
    "  * Pupil Center Corneal Reflection (PCCR) technique: common IR technique\n",
    "  * IR systems' downside:\n",
    "    * it can be affected by the sunshine in outdoor scenario.\n",
    "    * the relative position between the IR lights and the camera need to be calibrated carefully\n",
    "    * usually a high-resolution camera is needed (small pupil and glint)\n",
    "  * Face feature-based: overcome the need of high resolution cameras (face features are bigger than iris and pulpils)\n",
    "  * Just one camera to estimate the 3D eye features\n",
    "\n",
    "### 2. Gaze estimation algortithm\n",
    "  * Important: calculer the 3D position of the eyeball center $\\mathbf{C}$ based on the middle point $\\mathbf{M}$ of two eye corners $(\\mathbf{E}_1, \\mathbf{E}_2)$\n",
    "  ![3D eye model](3deyemodel.png)\n",
    "  * Eyeball: is made up of the segments of **two spheres** with **different sizes**\n",
    "  * Optical axis: 3D line connecting the corneal centre $\\mathbf{C}_0$ and the pupil centre $\\mathbf{P}$\n",
    "  * Gaze point: intersection of **visual axis** (rather than the optical axis) with the **scene**.\n",
    "  * Relationship between **visual** and **optical axis** should be modeled\n",
    "  * *kappa*: angle between visual and optical axis 3D\n",
    "  * offset vector $\\mathbf{V}$ between $\\mathbf{M}$ and $\\mathbf{C}$ is related to the face pose\n",
    "\n",
    "#### Step 1: Facial Feature Tracking and Face Pose Estimation\n",
    "  * Face pose vector $\\alpha = \\left ( \\sigma_\\text{pan}, \\phi_\\text{tilt}, \\kappa_\\text{swing},s \\right )$, three face pose angles and a scalar factor\n",
    "  * six rigid face points:\n",
    "  ![](rigid.png)\n",
    "  * the 3 face pose angles: define a 3×3 rotation matrix R to rotate the 3D face point from the face-model coordinate to the camera coordinate\n",
    "  * \n",
    "#### Step 2: Estimate the 3D point M\n",
    "\n",
    "#### Step 3: Compute 3D position of C\n",
    "  \n",
    "#### Step 4: Compute P\n",
    "\n",
    "#### Step 5: Compute Gaze\n",
    "\n",
    "\n",
    "**Obs.:** I intend to complete the notes above if necessary. In summary, there is a lot of geometry in the technique. Until this point, ok, nothing really new, but there are some steps in the calibration phase that can be tricky, and this can cause some trouble. *On should be aware of that !!*\n",
    "  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Paper 2\n",
    "**Title:** A Probabilistic Approach to Online Eye Gaze Tracking Without Explicit Personal Calibration\n",
    "\n",
    "**Authors:** Chen, Jixu and Ji, Qiang \n",
    "\n",
    "**Where:** IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 3, MARCH 2015\n",
    "\n",
    "**Year:** 2015\n",
    "\n",
    "**Keywords:** explicit personal calibration, feature approach, probabilistic eye gaze tracking, estimation of the probability distributions of the eye parameter and eye gaze, incremental learning framework, accuracy < 3°\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "### 1. Introduction:\n",
    "* *Probabilistic approach* for 3D eye gaze estimation without explicit personal calibration,\n",
    "* Development of an *incremental learning approach*\n",
    "* Development of a gaze estimation algorithm using *Gaussian prior probability*\n",
    "\n",
    "### 2. Related work:\n",
    "* appearance-based: simple to implement, suffers with  head movements\n",
    "* feature-based: \n",
    "  - 2D: 2D features to 3D gaze direction or 2D por by a polynomial function; do not cope well with head movements\n",
    "  - 3D: geometric model of the eye; invariant to head movements\n",
    "    + stereo cameras\n",
    "    + single cameras with multiple calibrated light sources\n",
    "    + still require personal calibration, because  rotation angles vary from person to person\n",
    "  - Implicity personal calibration\n",
    "* Prior gaze ditribution with 3D eye model\n",
    "* To overcome the limitations with the *saliency map*: replaced by a *Gaussian prior*\n",
    "\n",
    "### 3. 3D model-based gaze estimation\n",
    "#### A. 3D Eyeball Structure\n",
    "* optical axis: cornea centre, centre of pupil\n",
    "* visual axis: fovea; centre of cornea\n",
    "* $\\kappa$: angle between optical e visual axis (person-specific)\n",
    "\n",
    "#### B. Personal calibration\n",
    "* Calibration scheme: one single camera and two IR light sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
